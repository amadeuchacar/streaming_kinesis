# Projeto 2 - Engenharia de Dados

Projeto realizado no curso "*FormaÃ§Ã£o Engenharia de Dados: Domine Big Data!*".

## Objetivo ğŸ¯
- 1. Criar um produtor de dados, processar esses dados em streaming no AWS Kinesis Data Stream e criar um consumidor para estes dados.
- 2. Criar um produtor de dados e entregÃ¡-lo para o AWS Kinesis Data Firehose, para que este armazene os dados produzidos em um bucket S3.

## Requisitos ğŸ“„
- Credenciais de seguranÃ§a da AWS (chaves de acesso);
- Stream de dados criado no AWS Kinesis Data Stream;
- Entregador de dados AWS Kinesis Data Firehose criado, vinculado a um bucket S3;

## Desenvolvimento ğŸ‘¨ğŸ»â€ğŸ’»
### 1ï¸âƒ£ Primeira etapa
O notebook para a criaÃ§Ã£o de um produtor de dados estÃ¡ disponÃ­vel no arquivo "*produtor.ipynb*", presente neste repositÃ³rio;

O notebook para a criaÃ§Ã£o de um consumidor de dados estÃ¡ disponÃ­vel no arquivo "*consumidor1.ipynb*", presente neste repositÃ³rio;

Processo: O produtor irÃ¡ produzir dados, irÃ¡ enviÃ¡-lo para o Kinesis Data Stream em formato JSON, e o consumidor irÃ¡ consumi-lo;

### 2ï¸âƒ£ Segunda etapa
O notebook para a criaÃ§Ã£o de um produtor de dados estÃ¡ disponÃ­vel no arquivo "*produtor.ipynb*", presente neste repositÃ³rio;

O fluxo de entrega no AWS Kinesis Data Firehose deve estar criado e vinculado ao stream de dados do AWS Kinesis Data Stream, na plataforma da AWS;

Ao executar o produtor, os dados serÃ£o armazenados em um bucket S3 previamente configurado junto ao Firehose;

O arquivo gerado pelo produtor e armazenado no bucket S3 estÃ¡ disponÃ­vel no arquivo "*KDS-S3-n4hDk-2-2023-02-17-14-38-59-4a82c798-0b21-43db-887a-b8e2bc766ff3*", presente neste repositÃ³rio.
